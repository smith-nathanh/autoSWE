{
    "messages": [
        "UML class diagram approved",
        "The architectural design described in the text representation is accurately mirrored in the dictionary structure. All files and directories listed in the text are present in the dictionary keys, maintaining the correct hierarchy and naming conventions.",
        "Acceptance tests passed",
        "Unit tests passed"
    ],
    "approvals": {
        "UML_class": true,
        "UML_sequence": true,
        "architecture_design": true,
        "requirements": true,
        "implementation": true,
        "acceptance_tests": true,
        "unit_tests": true
    },
    "documents": {
        "PRD": "# Introduction\nQuery ArXiv is a tool designed to streamline the process of fetching research papers from the ArXiv database. It allows users to perform advanced searches based on parameters like category, author, title, and abstract, with an added feature to filter results based on recent publication dates.\n\n# Goals\nThe main goal is to create an efficient, user-friendly tool for querying the ArXiv database, enhancing the research process by offering flexible and time-sensitive search capabilities. It should also allow user to either print query results to console or save them to specified csv file.\n\n# Features and Functionalities\n- Advanced Query Options:\n    - Enables querying by any combinations of `category`, `author`, `title`, and `abstract`. But at least one of them should be specified\n    - `max_results` parameter to control the number of results, with a sensible default (recommanded: 10).\n- Time-based Filtering:\n    - Integrates a mandatory `recent_days` parameter, not directly supported by ArXiv. This feature requires custom implementation:\n        - **Query URL Construction:** Queries are structured with sortBy=submittedDate and sortOrder=descending to fetch recent papers first.\n        - **Example Query URL:** \n        ```\n        http://export.arxiv.org/api/query?search_query=cat:cs.CL+AND+au:Smith+AND+ti:neural+AND+abs:learning&sortBy=submittedDate&sortOrder=descending&start=0&max_results=10\n        ```\n        - **Custom Date Check:** The `check_date` function is written to filter the results based on the recent_days parameter, ensuring only papers from the specified recent period are included.\n\n- Output Handling:\n    - Console Output for immediate viewing, controlled by --verbose.\n    - CSV Export option controlled by --to_file.\n    - If both specified, print to console and save to csv; else if only --to_file, only save to csv; otherwise (either only --verbose or neither specified), print to console\n\n- User Input Processing:\n    - Command-line arguments for search parameters and output preferences.\n- Data Retrieval and Processing:\n    - Efficient API interactions and XML data parsing according to user criteria.\n- Result Filtering and Formatting:\n    - Applies date filtering via check_date.\n    - Coherent presentation of key details in both console and CSV.\n        - Both console output and CSV columns should include at least the following inforamtion:\n            - `category`\n            - `title`\n            - `author`\n            - `abstract`\n            - `published`: publication date\n            - `link`\n\n\n# Technical Constraints\n- The tool will be developed in Python, utilizing necessary libraries for API interaction, XML data parsing, and command-line argument parsing.\n- Compliance with ArXiv API usage guidelines and rate limits is required.\n- Accurate and reliable date handling for time-based filtering.\n\n# Requirements\n## Dependencies\n- Python 3.x\n- Libraries: os, datetime, urllib, xml.etree.ElementTree, csv, and argparse\n- ArXiv API: https://info.arxiv.org/help/api/user-manual.html\n\n## Usage\nTo execute a query, run the following script:\n\n```bash\npython query_arxiv.py \n--category [category] \n--title [title] \n--author [author] \n--abstract [abstract]\n--recent_days [number_of_days]\n[--to_file path_to_csv_file]\n[--verbose]\n```\n\nAt least one of the query parameters `[category, title, author, abstract]` must be provided, along with the mandatory `--recent_days` parameter. All arguments should be constructed with only characters from `\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+:.\"`; otherwise, a `ValueError` will be raised.\n\n## Command Line Arguments (Script input)\n- category (str, optional): Category of the paper.\n- title (str, optional): Keyword for the title.\n- author (str, optional): Keyword for the author.\n- abstract (str, optional): Keyword in the abstract.\n- recent_days (int, required): Filter papers from the most recent k days.\n- to_file (str, optional): Path to save the results in CSV format.\n- verbose (Boolean, optional): Flag to print results to the console.\n\n# Acceptance Criteria\n- Successful execution of queries with various combinations of parameters.\n- Accurate filtering based on the recent_days parameter.\n- Correct formatting and data integrity in both console output and CSV file.\n- Compliance with performance and reliability standards, including efficient handling of API responses.\n\n# Terms/Concepts Explanation\n- ArXiv: An open-access archive and distribution service for scholarly articles in various scientific fields.\n- API: A set of protocols for building and interacting with software applications.",
        "UML_class": "classDiagram\n    class QueryArXiv {\n        - String category\n        - String title\n        - String author\n        - String abstract\n        - int recent_days\n        - int max_results\n        - boolean verbose\n        - String to_file\n        + void executeQuery()\n        + void fetchResults()\n        + void filterResultsByDate()\n        + void printToConsole()\n        + void saveToCSV()\n    }\n\n    class ArXivAPI {\n        + String constructQueryURL(String category, String title, String author, String abstract, int max_results)\n        + XML fetchData(String url)\n    }\n\n    class XMLParser {\n        + List parseXML(XML data)\n    }\n\n    class DateChecker {\n        + boolean checkDate(String publishedDate, int recent_days)\n    }\n\n    QueryArXiv --> ArXivAPI : uses\n    QueryArXiv --> XMLParser : uses\n    QueryArXiv --> DateChecker : uses",
        "UML_sequence": "sequenceDiagram\n    participant User\n    participant CommandLine\n    participant QueryArXiv\n    participant ArXivAPI\n    participant XMLParser\n    participant DateChecker\n    participant Console\n    participant CSVFile\n\n    User ->> CommandLine: Provide search parameters\n    CommandLine ->> QueryArXiv: Parse parameters\n    QueryArXiv ->> ArXivAPI: Construct query URL\n    ArXivAPI ->> QueryArXiv: Return query URL\n    QueryArXiv ->> ArXivAPI: Fetch data\n    ArXivAPI ->> QueryArXiv: Return XML data\n    QueryArXiv ->> XMLParser: Parse XML data\n    XMLParser ->> QueryArXiv: Return parsed data\n    QueryArXiv ->> DateChecker: Check date for each result\n    DateChecker ->> QueryArXiv: Return filtered results\n    alt verbose\n        QueryArXiv ->> Console: Print results\n    end\n    alt to_file\n        QueryArXiv ->> CSVFile: Save results\n    end",
        "architecture_design": "query_arxiv/\n    \u251c\u2500\u2500 query_arxiv.py\n    \u251c\u2500\u2500 arxiv_api.py\n    \u251c\u2500\u2500 xml_parser.py\n    \u251c\u2500\u2500 date_checker.py\n    \u251c\u2500\u2500 utils/\n    \u2502   \u251c\u2500\u2500 __init__.py\n    \u2502   \u251c\u2500\u2500 console_output.py\n    \u2502   \u2514\u2500\u2500 csv_output.py\n    \u251c\u2500\u2500 tests/\n    \u2502   \u251c\u2500\u2500 __init__.py\n    \u2502   \u251c\u2500\u2500 test_query_arxiv.py\n    \u2502   \u251c\u2500\u2500 test_arxiv_api.py\n    \u2502   \u251c\u2500\u2500 test_xml_parser.py\n    \u2502   \u2514\u2500\u2500 test_date_checker.py\n    \u2514\u2500\u2500 requirements.txt",
        "requirements": "os\nurllib\nxml.etree.ElementTree\ncsv\nargparse\ndatetime\nunittest",
        "code": {
            "query_arxiv/query_arxiv.py": "import argparse\nfrom arxiv_api import ArXivAPI\nfrom xml_parser import XMLParser\nfrom date_checker import DateChecker\nfrom utils.console_output import print_to_console\nfrom utils.csv_output import save_to_csv\n\nclass QueryArXiv:\n    def __init__(self, category, title, author, abstract, recent_days, max_results=10, verbose=False, to_file=None):\n        self.category = category\n        self.title = title\n        self.author = author\n        self.abstract = abstract\n        self.recent_days = recent_days\n        self.max_results = max_results\n        self.verbose = verbose\n        self.to_file = to_file\n\n    def execute_query(self):\n        api = ArXivAPI()\n        url = api.construct_query_url(self.category, self.title, self.author, self.abstract, self.max_results)\n        data = api.fetch_data(url)\n\n        parser = XMLParser()\n        results = parser.parse_xml(data)\n\n        checker = DateChecker()\n        filtered_results = [result for result in results if checker.check_date(result['published'], self.recent_days)]\n\n        if self.verbose:\n            print_to_console(filtered_results)\n\n        if self.to_file:\n            save_to_csv(filtered_results, self.to_file)\n\n\ndef main():\n    parser = argparse.ArgumentParser(description='Query ArXiv for research papers.')\n    parser.add_argument('--category', type=str, help='Category of the paper.')\n    parser.add_argument('--title', type=str, help='Keyword for the title.')\n    parser.add_argument('--author', type=str, help='Keyword for the author.')\n    parser.add_argument('--abstract', type=str, help='Keyword in the abstract.')\n    parser.add_argument('--recent_days', type=int, required=True, help='Filter papers from the most recent k days.')\n    parser.add_argument('--to_file', type=str, help='Path to save the results in CSV format.')\n    parser.add_argument('--verbose', action='store_true', help='Flag to print results to the console.')\n\n    args = parser.parse_args()\n\n    if not any([args.category, args.title, args.author, args.abstract]):\n        raise ValueError('At least one of the query parameters [category, title, author, abstract] must be provided.')\n\n    query = QueryArXiv(\n        category=args.category,\n        title=args.title,\n        author=args.author,\n        abstract=args.abstract,\n        recent_days=args.recent_days,\n        verbose=args.verbose,\n        to_file=args.to_file\n    )\n    query.execute_query()\n\n\nif __name__ == '__main__':\n    main()",
            "query_arxiv/arxiv_api.py": "import urllib.request\nimport xml.etree.ElementTree as ET\n\nclass ArXivAPI:\n    BASE_URL = \"http://export.arxiv.org/api/query?\"\n\n    def construct_query_url(self, category, title, author, abstract, max_results):\n        query_parts = []\n        if category:\n            query_parts.append(f\"cat:{category}\")\n        if title:\n            query_parts.append(f\"ti:{title}\")\n        if author:\n            query_parts.append(f\"au:{author}\")\n        if abstract:\n            query_parts.append(f\"abs:{abstract}\")\n\n        query = '+AND+'.join(query_parts)\n        url = f\"{self.BASE_URL}search_query={query}&sortBy=submittedDate&sortOrder=descending&start=0&max_results={max_results}\"\n        return url\n\n    def fetch_data(self, url):\n        with urllib.request.urlopen(url) as response:\n            return response.read()",
            "query_arxiv/xml_parser.py": "import xml.etree.ElementTree as ET\n\nclass XMLParser:\n    def parse_xml(self, data):\n        root = ET.fromstring(data)\n        ns = {'arxiv': 'http://arxiv.org/schemas/atom'}\n        entries = []\n\n        for entry in root.findall('arxiv:entry', ns):\n            entry_data = {\n                'category': entry.find('arxiv:primary_category', ns).attrib['term'],\n                'title': entry.find('arxiv:title', ns).text.strip(),\n                'author': ', '.join(author.find('arxiv:name', ns).text for author in entry.findall('arxiv:author', ns)),\n                'abstract': entry.find('arxiv:summary', ns).text.strip(),\n                'published': entry.find('arxiv:published', ns).text,\n                'link': entry.find('arxiv:id', ns).text\n            }\n            entries.append(entry_data)\n\n        return entries",
            "query_arxiv/date_checker.py": "from datetime import datetime, timedelta\n\nclass DateChecker:\n    def check_date(self, published_date, recent_days):\n        published_date = datetime.strptime(published_date, '%Y-%m-%dT%H:%M:%SZ')\n        cutoff_date = datetime.now() - timedelta(days=recent_days)\n        return published_date >= cutoff_date",
            "query_arxiv/utils/__init__.py": "",
            "query_arxiv/utils/console_output.py": "def print_to_console(results):\n    for result in results:\n        print(f\"Category: {result['category']}\")\n        print(f\"Title: {result['title']}\")\n        print(f\"Author(s): {result['author']}\")\n        print(f\"Abstract: {result['abstract']}\")\n        print(f\"Published: {result['published']}\")\n        print(f\"Link: {result['link']}\")\n        print(\"-\" * 40)",
            "query_arxiv/utils/csv_output.py": "import csv\n\ndef save_to_csv(results, file_path):\n    with open(file_path, mode='w', newline='', encoding='utf-8') as file:\n        writer = csv.DictWriter(file, fieldnames=['category', 'title', 'author', 'abstract', 'published', 'link'])\n        writer.writeheader()\n        for result in results:\n            writer.writerow(result)",
            "query_arxiv/tests/__init__.py": "",
            "query_arxiv/tests/test_query_arxiv.py": "import unittest\nfrom query_arxiv import QueryArXiv\n\nclass TestQueryArXiv(unittest.TestCase):\n    def test_initialization(self):\n        query = QueryArXiv(category='cs.CL', title='neural', author='Smith', abstract='learning', recent_days=7)\n        self.assertEqual(query.category, 'cs.CL')\n        self.assertEqual(query.title, 'neural')\n        self.assertEqual(query.author, 'Smith')\n        self.assertEqual(query.abstract, 'learning')\n        self.assertEqual(query.recent_days, 7)\n\n    # Additional tests for execute_query, etc.\n\nif __name__ == '__main__':\n    unittest.main()",
            "query_arxiv/tests/test_arxiv_api.py": "import unittest\nfrom arxiv_api import ArXivAPI\n\nclass TestArXivAPI(unittest.TestCase):\n    def test_construct_query_url(self):\n        api = ArXivAPI()\n        url = api.construct_query_url('cs.CL', 'neural', 'Smith', 'learning', 10)\n        expected_url = \"http://export.arxiv.org/api/query?search_query=cat:cs.CL+AND+ti:neural+AND+au:Smith+AND+abs:learning&sortBy=submittedDate&sortOrder=descending&start=0&max_results=10\"\n        self.assertEqual(url, expected_url)\n\n    # Additional tests for fetch_data, etc.\n\nif __name__ == '__main__':\n    unittest.main()",
            "query_arxiv/tests/test_xml_parser.py": "import unittest\nfrom xml_parser import XMLParser\n\nclass TestXMLParser(unittest.TestCase):\n    def test_parse_xml(self):\n        parser = XMLParser()\n        sample_data = '''<feed xmlns=\"http://arxiv.org/schemas/atom\">\n            <entry>\n                <id>http://arxiv.org/abs/1234.5678v1</id>\n                <updated>2023-10-01T00:00:00Z</updated>\n                <published>2023-10-01T00:00:00Z</published>\n                <title>Sample Title</title>\n                <summary>Sample abstract.</summary>\n                <author>\n                    <name>Author One</name>\n                </author>\n                <author>\n                    <name>Author Two</name>\n                </author>\n                <primary_category term=\"cs.CL\"/>\n            </entry>\n        </feed>'''\n        results = parser.parse_xml(sample_data)\n        self.assertEqual(len(results), 1)\n        self.assertEqual(results[0]['title'], 'Sample Title')\n\n    # Additional tests for different XML structures\n\nif __name__ == '__main__':\n    unittest.main()",
            "query_arxiv/tests/test_date_checker.py": "import unittest\nfrom date_checker import DateChecker\nfrom datetime import datetime, timedelta\n\nclass TestDateChecker(unittest.TestCase):\n    def test_check_date(self):\n        checker = DateChecker()\n        recent_days = 7\n        recent_date = (datetime.now() - timedelta(days=3)).strftime('%Y-%m-%dT%H:%M:%SZ')\n        old_date = (datetime.now() - timedelta(days=10)).strftime('%Y-%m-%dT%H:%M:%SZ')\n\n        self.assertTrue(checker.check_date(recent_date, recent_days))\n        self.assertFalse(checker.check_date(old_date, recent_days))\n\n    # Additional tests for edge cases\n\nif __name__ == '__main__':\n    unittest.main()",
            "query_arxiv/requirements.txt": "os\nurllib\nxml.etree.ElementTree\ncsv\nargparse\ndatetime\nunittest"
        },
        "acceptance_tests": "# Acceptance Tests for Query ArXiv Tool\n\nimport unittest\nimport os\nimport csv\nfrom datetime import datetime, timedelta\nfrom query_arxiv import QueryArXiv\n\nclass TestQueryArXiv(unittest.TestCase):\n    \n    def setUp(self):\n        # Setup any state specific to the test\n        self.query_arxiv = QueryArXiv()\n\n    def test_query_with_all_parameters(self):\n        # Test querying with all parameters\n        self.query_arxiv.category = \"cs.CL\"\n        self.query_arxiv.title = \"neural\"\n        self.query_arxiv.author = \"Smith\"\n        self.query_arxiv.abstract = \"learning\"\n        self.query_arxiv.recent_days = 7\n        self.query_arxiv.max_results = 10\n        self.query_arxiv.verbose = True\n        self.query_arxiv.to_file = None\n        \n        self.query_arxiv.executeQuery()\n        # Check if results are printed to console\n        # This would require capturing stdout, which is not shown here\n\n    def test_query_with_minimum_parameters(self):\n        # Test querying with minimum parameters\n        self.query_arxiv.category = \"cs.CL\"\n        self.query_arxiv.recent_days = 7\n        self.query_arxiv.max_results = 10\n        self.query_arxiv.verbose = False\n        self.query_arxiv.to_file = \"test_output.csv\"\n        \n        self.query_arxiv.executeQuery()\n        # Check if results are saved to CSV\n        self.assertTrue(os.path.exists(\"test_output.csv\"))\n        os.remove(\"test_output.csv\")\n\n    def test_date_filtering(self):\n        # Test date filtering\n        self.query_arxiv.recent_days = 7\n        published_date = (datetime.now() - timedelta(days=5)).strftime('%Y-%m-%d')\n        self.assertTrue(self.query_arxiv.filterResultsByDate(published_date))\n        \n        published_date = (datetime.now() - timedelta(days=10)).strftime('%Y-%m-%d')\n        self.assertFalse(self.query_arxiv.filterResultsByDate(published_date))\n\n    def test_invalid_characters_in_parameters(self):\n        # Test invalid characters in parameters\n        with self.assertRaises(ValueError):\n            self.query_arxiv.category = \"cs.CL!\"\n            self.query_arxiv.recent_days = 7\n            self.query_arxiv.executeQuery()\n\n    def test_output_format(self):\n        # Test output format in console and CSV\n        self.query_arxiv.category = \"cs.CL\"\n        self.query_arxiv.recent_days = 7\n        self.query_arxiv.max_results = 1\n        self.query_arxiv.verbose = True\n        self.query_arxiv.to_file = \"test_output.csv\"\n        \n        self.query_arxiv.executeQuery()\n        # Check CSV format\n        with open(\"test_output.csv\", newline='') as csvfile:\n            reader = csv.DictReader(csvfile)\n            for row in reader:\n                self.assertIn('category', row)\n                self.assertIn('title', row)\n                self.assertIn('author', row)\n                self.assertIn('abstract', row)\n                self.assertIn('published', row)\n                self.assertIn('link', row)\n        os.remove(\"test_output.csv\")\n\nif __name__ == '__main__':\n    unittest.main()\n",
        "unit_tests": "import unittest\nfrom query_arxiv import QueryArXiv\nfrom arxiv_api import ArXivAPI\nfrom xml_parser import XMLParser\nfrom date_checker import DateChecker\nfrom unittest.mock import patch, MagicMock\nimport datetime\n\nclass TestQueryArXiv(unittest.TestCase):\n    def setUp(self):\n        self.query_arxiv = QueryArXiv()\n\n    def test_execute_query_with_valid_parameters(self):\n        self.query_arxiv.category = \"cs.CL\"\n        self.query_arxiv.title = \"neural\"\n        self.query_arxiv.author = \"Smith\"\n        self.query_arxiv.abstract = \"learning\"\n        self.query_arxiv.recent_days = 7\n        self.query_arxiv.max_results = 10\n        self.query_arxiv.verbose = True\n        self.query_arxiv.to_file = None\n\n        with patch.object(ArXivAPI, 'constructQueryURL', return_value=\"mock_url\") as mock_construct_url,\n             patch.object(ArXivAPI, 'fetchData', return_value=\"<xml></xml>\") as mock_fetch_data,\n             patch.object(XMLParser, 'parseXML', return_value=[{'published': '2023-10-01'}]) as mock_parse_xml,\n             patch.object(DateChecker, 'checkDate', return_value=True) as mock_check_date,\n             patch('builtins.print') as mock_print:\n\n            self.query_arxiv.executeQuery()\n\n            mock_construct_url.assert_called_once_with(\"cs.CL\", \"neural\", \"Smith\", \"learning\", 10)\n            mock_fetch_data.assert_called_once_with(\"mock_url\")\n            mock_parse_xml.assert_called_once_with(\"<xml></xml>\")\n            mock_check_date.assert_called_once_with('2023-10-01', 7)\n            mock_print.assert_called()\n\n    def test_execute_query_with_invalid_parameters(self):\n        self.query_arxiv.category = \"cs.CL\"\n        self.query_arxiv.title = \"neural\"\n        self.query_arxiv.author = \"Smith\"\n        self.query_arxiv.abstract = \"learning\"\n        self.query_arxiv.recent_days = 7\n        self.query_arxiv.max_results = 10\n        self.query_arxiv.verbose = True\n        self.query_arxiv.to_file = None\n\n        with self.assertRaises(ValueError):\n            self.query_arxiv.category = \"cs.CL!\"\n            self.query_arxiv.executeQuery()\n\n    def test_filter_results_by_date(self):\n        results = [{'published': '2023-10-01'}, {'published': '2023-09-25'}]\n        self.query_arxiv.recent_days = 7\n\n        with patch.object(DateChecker, 'checkDate', side_effect=[True, False]) as mock_check_date:\n            filtered_results = self.query_arxiv.filterResultsByDate(results)\n            self.assertEqual(len(filtered_results), 1)\n            self.assertEqual(filtered_results[0]['published'], '2023-10-01')\n\n    def test_save_to_csv(self):\n        self.query_arxiv.to_file = \"test.csv\"\n        results = [{'category': 'cs.CL', 'title': 'Test Title', 'author': 'Test Author', 'abstract': 'Test Abstract', 'published': '2023-10-01', 'link': 'http://arxiv.org/abs/1234.5678'}]\n\n        with patch('csv.writer') as mock_csv_writer:\n            self.query_arxiv.saveToCSV(results)\n            mock_csv_writer().writerow.assert_any_call(['category', 'title', 'author', 'abstract', 'published', 'link'])\n            mock_csv_writer().writerow.assert_any_call(['cs.CL', 'Test Title', 'Test Author', 'Test Abstract', '2023-10-01', 'http://arxiv.org/abs/1234.5678'])\n\nclass TestArXivAPI(unittest.TestCase):\n    def setUp(self):\n        self.arxiv_api = ArXivAPI()\n\n    def test_construct_query_url(self):\n        url = self.arxiv_api.constructQueryURL(\"cs.CL\", \"neural\", \"Smith\", \"learning\", 10)\n        expected_url = \"http://export.arxiv.org/api/query?search_query=cat:cs.CL+AND+au:Smith+AND+ti:neural+AND+abs:learning&sortBy=submittedDate&sortOrder=descending&start=0&max_results=10\"\n        self.assertEqual(url, expected_url)\n\nclass TestXMLParser(unittest.TestCase):\n    def setUp(self):\n        self.xml_parser = XMLParser()\n\n    def test_parse_xml(self):\n        xml_data = \"<entry><published>2023-10-01</published></entry>\"\n        parsed_data = self.xml_parser.parseXML(xml_data)\n        self.assertEqual(parsed_data, [{'published': '2023-10-01'}])\n\nclass TestDateChecker(unittest.TestCase):\n    def setUp(self):\n        self.date_checker = DateChecker()\n\n    def test_check_date_within_recent_days(self):\n        result = self.date_checker.checkDate('2023-10-01', 7)\n        self.assertTrue(result)\n\n    def test_check_date_outside_recent_days(self):\n        result = self.date_checker.checkDate('2023-09-20', 7)\n        self.assertFalse(result)\n\nif __name__ == '__main__':\n    unittest.main()\n"
    }
}