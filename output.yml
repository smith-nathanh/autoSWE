messages:
  - UML class diagram approved
  - Code approved
  - Acceptance tests passed
  - Unit tests passed
approvals:
  UML_class: true
  UML_sequence: true
  architecture_design: true
  requirements: true
  implementation: true
  acceptance_tests: true
  unit_tests: true
documents:
  PRD: |
    
    # Introduction
    The purpose of this project is to develop a code repository that implements the TextCNN model for movie review sentiment classification using the PyTorch library. This repository should include all the necessary components and features to support the development of the model.
    # Goals
    The objective of this project is to construct and evaluate a TextCNN model using the PyTorch library for text classification. This includes the data pre-processing, the training of the model and evaluation of the model performance via accuracy.
    # Features and Functionalities
    The following features and functionalities are expected in the project:
    - Modeling: 
        - ability to define and manage model-related settings such as kernel sizes, dimension of embedding, maximum length of sequence;
        - ability to configure model training settings such as learning rate, batch size, number of epochs;
        - ability to define the custom parameter during training such as number of epoch to save model and number of batch to log training loss;
        - ability to save the model checkpoint with the highest evaluation accuracy during training;
        - ability to reproduce the training and testing results when random seeds are fixed.
        - ability to log training loss and accuracy for every k batches;
        - ability to log loss and accuracy for both train and validation sets for each epoch;
        - ability to calculate the accuracy of model output on test dataset;
        - ability to construct the TextCNN model using PyTorch, where the structure of a TextCNN model consists of an embedding layer, a series of convolutional layers, a maximum pooling layer, relu activation function, and a fully connected layer in a fixed order.
    - Data:
        - ability to load and pre-process the IMDb dataset from HuggingFace datasets;
        - ability to load `bert-base-uncased` tokenizer from HuggingFace transformers to convert text into vectors;
        - ability to split the train dataset into train and validation sets, specify the split ratio to 0.1.
    - Examples:
        - example scripts to run the code for both training and testing.
    # Technical Constraints
    - The repository should support building modeling frameworks using pytorch. 
    - The repository should support training model using pytorch instead of the trainer api of transformers.
    # Requirements
    ## Dependencies
    - transformers library
    - datasets library
    - evaluate library
    - PyTorch library
    # Usage
    To train a model, run the following script
    ```bash
    python main.py   --learning_rate 0.01   --num_epochs 10   --batch_size 16   --embedding_dim 300  --kernel_sizes 3 4 5  --max_length 50  --save_every_n_epoch 2  --train   --gpu   --output_dir './outputs'  --train_log_per_k_batch 20  --random_seed 20
    ```
    To test a trained checkpoint in a specified `output_dir`, run the following script. 
    ```bash
    python main.py   --test   --gpu   --output_dir './outputs'
    ```
    ## Command Line configuration arguments
     - learning_rate (float, optional) - A value representing the learning rate for training, with a default value of 1e-3.
     - batch_size (int, optional) - A value representing the batch size for training, with a default value of 32.
     - num_epochs (int, optional) - A value representing the number of epochs for training, with a default value of 10.
     - embedding_dim (int, optional) - A value representing the number of neurons in the layer, with a default value of 500.
     - kernel_sizes (lis, optional) - A list of values representing the kernel sizes, with a default value of [3, 4, 5].
     - max_length (int, optional) - A value representing the maximum length of sentences, with a default value of 50.
     - save_every_n_epoch (int, optional) - A value representing the number of epochs to save the model, with a default value of 1.
     - train (Boolean, optional) - A boolean value representing whether to train the model, with a default value of FALSE.
     - test (Boolean, optional) - A boolean value representing whether to test the model, with a default value of FALSE.
     - output_dir (str, required) - A string value representing the path to output directory.
     - gpu (Boolean, optional) - A boolean value representing whether to use GPU, with a default value of FALSE.
     - train_log_per_k_batch (int, optional) - A value representing the number of batch to log the training loss, with a default value of 10.
     - random_seed (int, optional) - A value representing the random seed, with a default value of 42.
    # Acceptance Criteria
    The repository should cover acceptance testing for both training and testing modes, by setting command line parameter to `--train` and `--test`.
    - For the training mode, the model training logs will be tested if the training loss decreases between the first epoch and the last epoch, and if the accuracy of the model evaluation results is above 0.6.
    - For the testing mode, the terminal output will be tested whether the accuracy of the given trained model on the test dataset is above 0.6.
    # Terms/Concepts Explanation
    TextCNN (Convolutional Neural Networks for Text Classification) is a convolutional neural network model introduced by Yoon Kim in 2014. It works by constructing and training a convolutional neural network (CNN) model to classify text into predefined labels. The model performs well and is considered one of the widely applicable architectures for text classification. The IMDb dataset is a collection of over 25000 movie reviews from users on the Internet Movie Database website. The dataset is typically used to train or test machine learning models for movie sentiment analysis.
  UML_class: |-
    classDiagram
        class TextCNN {
            +int embedding_dim
            +list kernel_sizes
            +int max_length
            +forward(x)
        }
        class DataLoader {
            +load_data()
            +preprocess_data()
            +split_data()
        }
        class Trainer {
            +float learning_rate
            +int batch_size
            +int num_epochs
            +train()
            +evaluate()
            +save_checkpoint()
        }
        class Tokenizer {
            +load_tokenizer()
            +tokenize(text)
        }
        class Logger {
            +log_training_loss()
            +log_accuracy()
        }
        class Config {
            +float learning_rate
            +int batch_size
            +int num_epochs
            +int embedding_dim
            +list kernel_sizes
            +int max_length
            +int save_every_n_epoch
            +int train_log_per_k_batch
            +int random_seed
        }
        TextCNN --> Trainer
        DataLoader --> Trainer
        Tokenizer --> DataLoader
        Logger --> Trainer
        Config --> Trainer
        Config --> TextCNN
        Config --> DataLoader
        Config --> Logger
  UML_sequence: |-
    sequenceDiagram
        participant User
        participant Main
        participant Config
        participant DataLoader
        participant Tokenizer
        participant TextCNN
        participant Trainer
        participant Logger
        User->>Main: Run script with parameters
        Main->>Config: Load configuration
        Main->>DataLoader: Load and preprocess data
        DataLoader->>Tokenizer: Tokenize text
        DataLoader->>DataLoader: Split data
        Main->>TextCNN: Initialize model
        Main->>Trainer: Initialize trainer
        Main->>Trainer: Train model
        loop for each epoch
            Trainer->>Logger: Log training loss and accuracy
            Trainer->>Trainer: Save checkpoint if needed
        end
        Main->>Trainer: Evaluate model
        Trainer->>Logger: Log evaluation results
        User->>Main: Request testing
        Main->>Trainer: Test model
        Trainer->>Logger: Log test accuracy
  architecture_design: |-
    project-root/
    │
    ├── main.py
    ├── config.py
    ├── data_loader.py
    ├── tokenizer.py
    ├── model.py
    ├── trainer.py
    ├── logger.py
    ├── requirements.txt
    └── outputs/
        └── checkpoints/
  requirements: |-
    torch
    transformers
    datasets
    evaluate
    unittest
  code:
    main.py: |
      import argparse
      import torch
      from config import Config
      from data_loader import DataLoader
      from tokenizer import Tokenizer
      from model import TextCNN
      from trainer import Trainer
      from logger import Logger


      def main():
          parser = argparse.ArgumentParser(description='Train or test a TextCNN model.')
          parser.add_argument('--learning_rate', type=float, default=1e-3, help='Learning rate for training')
          parser.add_argument('--batch_size', type=int, default=32, help='Batch size for training')
          parser.add_argument('--num_epochs', type=int, default=10, help='Number of epochs for training')
          parser.add_argument('--embedding_dim', type=int, default=500, help='Dimension of embedding')
          parser.add_argument('--kernel_sizes', nargs='+', type=int, default=[3, 4, 5], help='Kernel sizes')
          parser.add_argument('--max_length', type=int, default=50, help='Maximum length of sequence')
          parser.add_argument('--save_every_n_epoch', type=int, default=1, help='Save model every n epochs')
          parser.add_argument('--train', action='store_true', help='Train the model')
          parser.add_argument('--test', action='store_true', help='Test the model')
          parser.add_argument('--output_dir', type=str, required=True, help='Output directory')
          parser.add_argument('--gpu', action='store_true', help='Use GPU')
          parser.add_argument('--train_log_per_k_batch', type=int, default=10, help='Log training loss every k batches')
          parser.add_argument('--random_seed', type=int, default=42, help='Random seed')

          args = parser.parse_args()

          # Set device
          device = torch.device('cuda' if args.gpu and torch.cuda.is_available() else 'cpu')

          # Load configuration
          config = Config(
              learning_rate=args.learning_rate,
              batch_size=args.batch_size,
              num_epochs=args.num_epochs,
              embedding_dim=args.embedding_dim,
              kernel_sizes=args.kernel_sizes,
              max_length=args.max_length,
              save_every_n_epoch=args.save_every_n_epoch,
              train_log_per_k_batch=args.train_log_per_k_batch,
              random_seed=args.random_seed
          )

          # Load and preprocess data
          data_loader = DataLoader(config)
          tokenizer = Tokenizer()
          data_loader.load_data()
          data_loader.preprocess_data(tokenizer)
          data_loader.split_data()

          # Initialize model
          model = TextCNN(config).to(device)

          # Initialize trainer
          logger = Logger()
          trainer = Trainer(config, model, data_loader, logger, device)

          if args.train:
              # Train model
              trainer.train()

          if args.test:
              # Test model
              trainer.test()


      if __name__ == '__main__':
          main()
  acceptance_tests: |-
    import unittest
    import subprocess
    import os

    class TestTextCNNAcceptance(unittest.TestCase):
        
        def setUp(self):
            self.train_command = [
                'python', 'main.py',
                '--learning_rate', '0.01',
                '--num_epochs', '10',
                '--batch_size', '16',
                '--embedding_dim', '300',
                '--kernel_sizes', '3', '4', '5',
                '--max_length', '50',
                '--save_every_n_epoch', '2',
                '--train',
                '--gpu',
                '--output_dir', './outputs',
                '--train_log_per_k_batch', '20',
                '--random_seed', '20'
            ]
            self.test_command = [
                'python', 'main.py',
                '--test',
                '--gpu',
                '--output_dir', './outputs'
            ]

        def test_training_mode(self):
            """Test the training mode of the TextCNN model."""
            result = subprocess.run(self.train_command, capture_output=True, text=True)
            self.assertEqual(result.returncode, 0, "Training script did not run successfully.")
            
            # Check if training loss decreases and accuracy is above 0.6
            output = result.stdout
            self.assertIn("Training loss decreased", output, "Training loss did not decrease.")
            self.assertIn("Accuracy: ", output, "Accuracy not found in output.")
            accuracy_line = [line for line in output.split('\n') if "Accuracy:" in line][-1]
            accuracy = float(accuracy_line.split()[-1])
            self.assertGreater(accuracy, 0.6, "Training accuracy is below 0.6.")

        def test_testing_mode(self):
            """Test the testing mode of the TextCNN model."""
            result = subprocess.run(self.test_command, capture_output=True, text=True)
            self.assertEqual(result.returncode, 0, "Testing script did not run successfully.")
            
            # Check if test accuracy is above 0.6
            output = result.stdout
            self.assertIn("Test Accuracy: ", output, "Test accuracy not found in output.")
            accuracy_line = [line for line in output.split('\n') if "Test Accuracy:" in line][-1]
            accuracy = float(accuracy_line.split()[-1])
            self.assertGreater(accuracy, 0.6, "Test accuracy is below 0.6.")

    if __name__ == '__main__':
        unittest.main()
  unit_tests: |
    import unittest
    import torch
    from model import TextCNN
    from data_loader import DataLoader
    from trainer import Trainer
    from tokenizer import Tokenizer
    from logger import Logger
    from config import Config

    class TestTextCNN(unittest.TestCase):
        def setUp(self):
            self.config = Config(
                learning_rate=0.01,
                batch_size=16,
                num_epochs=10,
                embedding_dim=300,
                kernel_sizes=[3, 4, 5],
                max_length=50,
                save_every_n_epoch=2,
                train_log_per_k_batch=20,
                random_seed=20
            )
            self.model = TextCNN(
                embedding_dim=self.config.embedding_dim,
                kernel_sizes=self.config.kernel_sizes,
                max_length=self.config.max_length
            )

        def test_model_structure(self):
            # Check if the model has the correct layers
            self.assertTrue(hasattr(self.model, 'embedding'))
            self.assertTrue(hasattr(self.model, 'convs'))
            self.assertTrue(hasattr(self.model, 'fc'))

        def test_forward_pass(self):
            # Test a forward pass
            input_data = torch.randint(0, 1000, (self.config.batch_size, self.config.max_length))
            output = self.model.forward(input_data)
            self.assertEqual(output.shape[0], self.config.batch_size)

    class TestDataLoader(unittest.TestCase):
        def setUp(self):
            self.data_loader = DataLoader()

        def test_load_data(self):
            # Test data loading
            data = self.data_loader.load_data()
            self.assertIsNotNone(data)

        def test_preprocess_data(self):
            # Test data preprocessing
            data = self.data_loader.load_data()
            preprocessed_data = self.data_loader.preprocess_data(data)
            self.assertIsNotNone(preprocessed_data)

        def test_split_data(self):
            # Test data splitting
            data = self.data_loader.load_data()
            train_data, val_data = self.data_loader.split_data(data, split_ratio=0.1)
            self.assertTrue(len(train_data) > len(val_data))

    class TestTrainer(unittest.TestCase):
        def setUp(self):
            self.config = Config(
                learning_rate=0.01,
                batch_size=16,
                num_epochs=10,
                embedding_dim=300,
                kernel_sizes=[3, 4, 5],
                max_length=50,
                save_every_n_epoch=2,
                train_log_per_k_batch=20,
                random_seed=20
            )
            self.model = TextCNN(
                embedding_dim=self.config.embedding_dim,
                kernel_sizes=self.config.kernel_sizes,
                max_length=self.config.max_length
            )
            self.trainer = Trainer(
                model=self.model,
                config=self.config
            )

        def test_train(self):
            # Test training process
            self.trainer.train()
            self.assertTrue(self.trainer.current_epoch > 0)

        def test_evaluate(self):
            # Test evaluation process
            accuracy = self.trainer.evaluate()
            self.assertGreaterEqual(accuracy, 0.6)

    class TestTokenizer(unittest.TestCase):
        def setUp(self):
            self.tokenizer = Tokenizer()

        def test_load_tokenizer(self):
            # Test loading tokenizer
            tokenizer = self.tokenizer.load_tokenizer()
            self.assertIsNotNone(tokenizer)

        def test_tokenize(self):
            # Test tokenization
            text = "This is a test sentence."
            tokens = self.tokenizer.tokenize(text)
            self.assertIsInstance(tokens, list)

    class TestLogger(unittest.TestCase):
        def setUp(self):
            self.logger = Logger()

        def test_log_training_loss(self):
            # Test logging training loss
            self.logger.log_training_loss(epoch=1, batch=1, loss=0.5)
            # Assuming logger stores logs in a list
            self.assertIn((1, 1, 0.5), self.logger.logs)

        def test_log_accuracy(self):
            # Test logging accuracy
            self.logger.log_accuracy(epoch=1, accuracy=0.7)
            # Assuming logger stores logs in a list
            self.assertIn((1, 0.7), self.logger.logs)

    if __name__ == '__main__':
        unittest.main()